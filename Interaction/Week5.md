## Evaluating

##### Design life cycle:
    1. Discovering requirements
    2. Designing alternatives
    3. Prototyping
    4. Evaluation

##### Evalutation:
    two types in total
    Find Usability problem
    Analytic Evaluation:
        Heuristic Evaluation -> Inspection method
        Involve no users, but experts

###### Developed by Jakob Nielson -> Nielsen Norman Group

##### Heuristic
    Define: Rule of Thumb / Aid to discovery (Very broad design guideline)
    1: Visibility of system status
    2: Match between system and real world
    3: User control and freedom
    4: Consistency and standards
    5: Error prevention
    6: Recognition rather than recall
    7: Flexibility and efficiency of use
    8: Aesthetic and minimalist design
    9: Help users recognise, diagnose and recover from errors
    10: Help and documentation

    Use 10 heuristics to spot problems:
    Identify source
    Identify solution
    Prioritize solutions

##### Conduct Heuristic Evaluation
    1. Train experts
    2. Get experts to use heuristic to find problem
    3. Permit experts to generate new heuristics
    4. Get experts to prioritise problems from 0 - 4
    5. Collect reports to single evaluation

##### Priority rating scale
    0 = False positive (not a problem)
    1 = Cosmetic problem (only solve when have extra time)
    2 = minor usability problem (low priority)
    3 = Major usability problem (High priority)
    4 = Usability catastrophe (imperative to fix)
    
###### Alternative rating scale see E Lecture

##### Number of evaluators
    3 - 5 is optimal
    
##### Advantages of Heuristic Evaluation
    Few ethical problems (No users)
    Few practical problems (Only on usability, no users)
    Fast
    Cheap (discount usability)
##### Disadvantages
    Important problems missed
    Trivial problems often identified
    Expert biased
    Difficult and expensive to find or train experts
    Not good for collaborative apps
    Not good for physical devices
